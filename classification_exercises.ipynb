{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - 3. Set up repo and .gitignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Make a new repo called classification-exercises on both GitHub and within your codeup-data-science directory. This will be where you do your work for this module.\n",
    "\n",
    "#### 2. Inside of your local classification-exercises repo, create a file named .gitignore with the following contents:\n",
    "\n",
    "```\n",
    "env.py\n",
    ".DS_Store\n",
    ".ipynb_checkpoints/\n",
    "__pycache__\n",
    "*.csv\n",
    "```\n",
    "\n",
    "#### Add and commit your .gitignore file before moving forward.\n",
    "\n",
    "#### 3. Now that you are 100% sure that your .gitignore file lists env.py, create or copy your env.py file inside of classification-exercises. Running git status should show that git is ignoring this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. In a jupyter notebook, classification_exercises.ipynb, use a python module (pydata or seaborn datasets) containing datasets as a source from the iris data. Create a pandas dataframe, df_iris, from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydataset import data\n",
    "\n",
    "iris = data('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
      "1           5.1          3.5           1.4          0.2  setosa\n",
      "2           4.9          3.0           1.4          0.2  setosa\n",
      "3           4.7          3.2           1.3          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "# 4a. print the first 3 rows\n",
    "\n",
    "print(iris.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "# 4b. print the number of rows and columns (shape)\n",
    "\n",
    "print(iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width',\n",
      "       'Species'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 4c. print the column names\n",
    "\n",
    "print(iris.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepal.Length    float64\n",
      "Sepal.Width     float64\n",
      "Petal.Length    float64\n",
      "Petal.Width     float64\n",
      "Species          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 4d. print the data type of each column\n",
    "\n",
    "print(iris.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "# 4e. print the summary statistics for each of the numeric variables\n",
    "\n",
    "print(iris.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Read the data from this google sheet into a dataframe, df_google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit#gid=341089357'\n",
    "\n",
    "csv_export_url = url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "\n",
    "df_google = pd.read_csv(csv_export_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# 5a. print the first 3 rows\n",
    "\n",
    "print(df_google.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "# 5b. print the number of rows and columns\n",
    "\n",
    "print(df_google.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#5c. print the column names\n",
    "\n",
    "print(df_google.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 5d. print the data type of each column\n",
    "\n",
    "print(df_google.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of      PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                    Name     Sex   Age  SibSp  \\\n",
      "0                                Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
      "2                                 Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3           Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                               Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                   ...     ...   ...    ...   \n",
      "886                                Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                         Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888             Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                                Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                  Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]>\n"
     ]
    }
   ],
   "source": [
    "# 5e. print the summary statistics for each of the numeric variables\n",
    "\n",
    "print(df_google.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Name   Sex  Ticket    Cabin Embarked\n",
      "count                       891   891     891      204      889\n",
      "unique                      891     2     681      147        3\n",
      "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
      "freq                          1   577       7        4      644\n"
     ]
    }
   ],
   "source": [
    "# 5f. print the unique values for each of your categorical variables\n",
    "\n",
    "print(df_google.describe(include='object'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Download the previous exercise's file into an excel (File → Download → Microsoft Excel). Read the downloaded file into a dataframe named df_excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6a. assign the first 100 rows to a new dataframe, df_excel_sample\n",
    "\n",
    "df_excel = pd.read_excel('train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "# 6b. print the number of rows of your original dataframe\n",
    "\n",
    "print(df_excel.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 6c. print the first 5 column names\n",
    "\n",
    "print(df_excel.columns[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 6d. print the column names that have a data type of object\n",
    "\n",
    "print(df_excel.select_dtypes(include='object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range for PassengerId: 890\n",
      "Range for Survived: 1\n",
      "Range for Pclass: 2\n",
      "Range for Age: 79.58\n",
      "Range for SibSp: 8\n",
      "Range for Parch: 6\n",
      "Range for Fare: 512.3292\n"
     ]
    }
   ],
   "source": [
    "# 6e. compute the range for each of the numeric variables.\n",
    "\n",
    "for col in df_excel.select_dtypes(include='number'):\n",
    "    col_range = df_excel[col].max() - df_excel[col].min()\n",
    "    print(f\"Range for {col}: {col_range}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Make a new python module, acquire.py to hold the following data aquisition functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire as a\n",
    "\n",
    "# Make a function named get_titanic_data that returns the titanic data from the codeup data science database as a pandas data frame. \n",
    "# Obtain your data from the Codeup Data Science Database.\n",
    "titanic = a.get_titanic_data()\n",
    "\n",
    "# Make a function named get_iris_data that returns the data from the iris_db on the codeup data science database as a pandas data frame. \n",
    "# The returned data frame should include the actual name of the species in addition to the species_ids. \n",
    "# Obtain your data from the Codeup Data Science Database.\n",
    "iris = a.get_iris_data()\n",
    "\n",
    "# Make a function named get_telco_data that returns the data from the telco_churn database in SQL. \n",
    "# In your SQL, be sure to join contract_types, internet_service_types, payment_types tables with\n",
    "# the customers table, so that the resulting dataframe contains all the contract, payment, and \n",
    "# internet service options. Obtain your data from the Codeup Data Science Database.\n",
    "telco = a.get_telco_data()\n",
    "\n",
    "# Once you've got your get_titanic_data, get_iris_data, and get_telco_data functions written, \n",
    "# now it's time to add caching to them. To do this, edit the beginning of the function to check \n",
    "# for the local filename of telco.csv, titanic.csv, or iris.csv. If they exist, use the .csv file. \n",
    "# If the file doesn't exist, then produce the SQL and pandas necessary to create a dataframe,\n",
    "# then write the dataframe to a .csv file with the appropriate name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your data acquisition function, first check to see if the csv file exists. If it does, read from the csv file, otherwise get the data \"fresh\".\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "def get_titanic_data():\n",
    "    filename = \"titanic.csv\"\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        # Create the engine\n",
    "        engine = create_engine(get_connection('titanic_db'))\n",
    "\n",
    "        # Read the SQL query into a dataframe\n",
    "        df = pd.read_sql(text('SELECT * FROM passengers'), engine.connect())\n",
    "\n",
    "        # Write that dataframe to disk for later. Called \"caching\" the data for later.\n",
    "        df.to_file(filename)\n",
    "\n",
    "        # Return the dataframe to the calling code\n",
    "        return df  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
