{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "- For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "- Create a new notebook, logistic_regression, use it to answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.linear_model\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from acquire import get_titanic_data, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  is_female  \\\n",
       "0         0       3  22.0      1      0   7.2500      0          0   \n",
       "1         1       1  38.0      1      0  71.2833      0          1   \n",
       "2         1       3  26.0      0      0   7.9250      1          1   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  \n",
       "0                   False                     True  \n",
       "1                   False                    False  \n",
       "2                   False                     True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_titanic_data()\n",
    "\n",
    "# Missing ages\n",
    "avg_age = df.age.mean()\n",
    "df.age = df.age.fillna(avg_age)\n",
    "\n",
    "# Encode\n",
    "df[\"is_female\"] = (df.sex == \"female\").astype('int')\n",
    "\n",
    "# More encode\n",
    "dummy_df = pd.get_dummies(df[['embark_town']], dummy_na=False, drop_first=True)\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\"passenger_id\", \"deck\", \"class\", \"embarked\", \"sex\", \"embark_town\"])\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "is_female                  0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 498 (56.00000000000001% of 891)\n",
      "validate: 214 (24.0% of 891)\n",
      "test: 179 (20.0% of 891)\n"
     ]
    }
   ],
   "source": [
    "# Split the datasets\n",
    "train, validate, test = split_data(df, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make X and Y splits\n",
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Exploration Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived\n",
      "0    307\n",
      "1    191\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "print(train['survived'].value_counts())\n",
    "\n",
    "baseline_accuracy = (train.survived == 0).mean()\n",
    "round(baseline_accuracy, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. \n",
    "Create a model that includes only age, fare, and pclass. Does this model perform better than your baseline?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.616\n",
      "Logistic Regression using ['age', 'pclass', 'fare']\n",
      "Accuracy of Logistic Regression classifier on training set: 0.703\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "lr = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify the features we're using\n",
    "features = [\"age\", \"pclass\", \"fare\"]\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "# lr.fit(X_train[[\"age\", \"pclass\", \"fare\"]], y_train)\n",
    "lr.fit(X_train[features], y_train)\n",
    "\n",
    "# Since we .fit on a subset, we .predict on that same subset of features\n",
    "y_pred = lr.predict(X_train[features])\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 3))\n",
    "print(\"Logistic Regression using\", features)\n",
    "print('Accuracy of Logistic Regression classifier on training set:', round((lr.score(X_train[features], y_train)),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. \n",
    "Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.616\n",
      "Logistic Regression using ['age', 'pclass', 'fare', 'is_female']\n",
      "Accuracy of Logistic Regression classifier on training set: 0.813\n"
     ]
    }
   ],
   "source": [
    "# Create\n",
    "lr2 = LogisticRegression(random_state=123)\n",
    "\n",
    "# Features\n",
    "features = ['age', 'pclass', 'fare', 'is_female']\n",
    "\n",
    "# Fit \n",
    "lr2.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = lr2.predict(X_train[features])\n",
    "\n",
    "# Score\n",
    "print(\"Baseline is\", round(baseline_accuracy, 3))\n",
    "print('Logistic Regression using', features)\n",
    "print('Accuracy of Logistic Regression classifier on training set:', round((lr2.score(X_train[features], y_train)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. \n",
    "Try out other combinations of features and models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Test on: All Features\n",
      "Accuracy on training set: 0.8152610441767069\n"
     ]
    }
   ],
   "source": [
    "# All features, all default hyperparameters\n",
    "lr3 = LogisticRegression(random_state=123)\n",
    "\n",
    "lr3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr3.predict(X_train)\n",
    "\n",
    "accuracy = lr3.score(X_train, y_train)\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Test on: All Features\")\n",
    "print(f'Accuracy on training set:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Test on: All Features with class_weight='balanced'\n",
      "Accuracy on training set: 0.8032128514056225\n"
     ]
    }
   ],
   "source": [
    "# All features, but we'll use the class_weights to hold the actual ratios`\n",
    "lr4 = LogisticRegression(random_state=123, class_weight='balanced')\n",
    "\n",
    "lr4.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr4.predict(X_train)\n",
    "\n",
    "accuracy = lr4.score(X_train, y_train)\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Test on: All Features with class_weight='balanced'\")\n",
    "print(f'Accuracy on training set:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Test on: ['age']\n",
      "Accuracy on training set: 0.6164658634538153\n"
     ]
    }
   ],
   "source": [
    "# Only Age \n",
    "features = [\"age\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "lr5 = LogisticRegression(random_state=123)\n",
    "\n",
    "lr5.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = lr5.predict(X_train[features])\n",
    "\n",
    "accuracy = lr5.score(X_train[features], y_train)\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Test on:\", features)\n",
    "print(f'Accuracy on training set:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Test on: ['pclass']\n",
      "Accuracy on training set: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Only pclass\n",
    "features = [\"pclass\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "lr6 = LogisticRegression(random_state=123)\n",
    "\n",
    "lr6.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = lr6.predict(X_train[features])\n",
    "\n",
    "accuracy = lr6.score(X_train[features], y_train)\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Test on:\", features)\n",
    "print(f'Accuracy on training set:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Test on: All Features, C=0.0001\n",
      "Accuracy on training set: 0.6445783132530121\n"
     ]
    }
   ],
   "source": [
    "# All Features, C ~ 0\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "lr7 = LogisticRegression(random_state=123, C=0.0001)\n",
    "\n",
    "lr7.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr7.predict(X_train)\n",
    "accuracy = lr7.score(X_train, y_train)\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Test on: All Features, C=0.0001\")\n",
    "print(f'Accuracy on training set:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \n",
    "Use you best 3 models to predict and evaluate on your validate sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.616\n",
      "Accuracy is: 0.776\n",
      "Logistic Regression using ['age', 'pclass', 'fare', 'is_female']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       132\n",
      "           1       0.72      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.76      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "features = ['age', 'pclass', 'fare', 'is_female']\n",
    "\n",
    "y_pred = lr2.predict(X_validate[features])\n",
    "\n",
    "# Score\n",
    "print(\"Baseline is\", round(baseline_accuracy, 3))\n",
    "print('Accuracy is:', round(lr2.score(X_validate[features], y_validate), 3))\n",
    "print('Logistic Regression using', features)\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Accuracy is: 0.776\n",
      "Test on: All Features with class_weight='balanced'\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       132\n",
      "           1       0.70      0.72      0.71        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.77      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All features, but we'll use the class_weights to hold the actual ratios`\n",
    "y_pred = lr4.predict(X_validate)\n",
    "\n",
    "# Score\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print('Accuracy is:', round(lr4.score(X_validate, y_validate), 3))\n",
    "print(\"Test on: All Features with class_weight='balanced'\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Accuracy is: 0.776\n",
      "Test on: All Features, All Default\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.82       132\n",
      "           1       0.74      0.65      0.69        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.75      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All features, all default hyperparameters\n",
    "y_pred = lr3.predict(X_validate)\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print('Accuracy is:', round(lr3.score(X_validate, y_validate), 3))\n",
    "print(\"Test on: All Features, All Default\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Accuracy is: 0.771\n",
      "Test on: All Features with class_weight='balanced'\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       132\n",
      "           1       0.70      0.72      0.71        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.77      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All features, but we'll use the class_weights to hold the actual ratios`\n",
    "y_pred = lr4.predict(X_validate)\n",
    "\n",
    "# Score\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print('Accuracy is:', round(lr4.score(X_test, y_test), 3))\n",
    "print(\"Test on: All Features with class_weight='balanced'\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 1:\n",
    "How do different strategies for handling the missing values in the age column affect model performance?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2:\n",
    "How do different strategies for encoding sex affect model performance?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 3:\n",
    "scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "\n",
    "C=.01,.1,1,10,100,1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 4: \n",
    "How does scaling the data interact with your choice of C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- High interpretabability. It's explainable to others, i.e. it's useful for understanding the influence of several independent variables on a single outcome variable.\n",
    "\n",
    "- We can choose to ‘snap’ predictions to 0 and 1 via a rule (such as if < .5, 0 else 1) OR we can choose to use the output as is, which is a probability of being class 1.\n",
    "\n",
    "- It’s a fast model and is a good place to start with a benchmark for comparing with other classification algorithms.\n",
    "\n",
    "- Very efficient and does not require many computational resources. Runs fast.\n",
    "\n",
    "- Outputs clear predicted probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assumes all predictors are independent of each other.\n",
    "\n",
    "- Missing values must be dealt with prior to fitting the model.\n",
    "\n",
    "- We can’t solve non-linear problems with logistic regression since it’s decision surface is linear.\n",
    "\n",
    "- Not always as accurate as other classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
